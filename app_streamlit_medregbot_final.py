
import streamlit as st
import pickle
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from PIL import Image

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ----------------------
st.set_page_config(page_title="MedRegBot", layout="wide")

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø´Ø¹Ø§Ø±Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª Ù…Ø­Ù„ÙŠØ© ----------------------
logo_left = Image.open("easy medical device.jpeg")
logo_right = Image.open("fmpm.jpeg")

# ---------------------- ØªØµÙ…ÙŠÙ… Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¹Ù„ÙˆÙŠØ© ----------------------
col1, col2, col3 = st.columns([1, 4, 1])
with col1:
    st.image(logo_left, width=120)
with col2:
    st.markdown("<h1 style='text-align: center; color: #003366;'>MedRegBot</h1>", unsafe_allow_html=True)
    st.markdown("<h4 style='text-align: center; color: #005580;'>Votre assistant IA pour la rÃ©glementation des dispositifs mÃ©dicaux</h4>", unsafe_allow_html=True)
with col3:
    st.image(logo_right, width=100)
st.markdown("---")

# ---------------------- ØªØ­Ù…ÙŠÙ„ Embeddings ----------------------
with open("embeddings_from_drive.pkl", "rb") as f:
    data = pickle.load(f)

texts = [d["text"] for d in data]
sources = [d.get("source", "Inconnu")] * len(data)
embeddings = np.array([d["embedding"] for d in data])

model = SentenceTransformer("sentence-transformers/LaBSE")

# ---------------------- ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ----------------------
left, center, right = st.columns([2, 6, 2])

# ------ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙŠØ³Ø±: Ø§Ù„ØªØ§Ø±ÙŠØ® ------
with left:
    st.markdown("### ğŸ•“ Historique")
    if "history" in st.session_state:
        for i, (role, msg) in enumerate(st.session_state.history):
            if role == "user":
                st.markdown(f"ğŸ‘¤ {msg}")
            else:
                st.markdown(f"ğŸ¤– {msg}")

# ------ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆØ³Ø·: Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ------
with center:
    st.markdown("### ğŸ’¬ Chat")
    if "history" not in st.session_state:
        st.session_state.history = []

    for role, msg in st.session_state.history:
        with st.chat_message(role):
            st.markdown(msg)

    user_input = st.chat_input("Posez votre question ici...")
    if user_input:
        st.session_state.history.append(("user", user_input))

        # Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø£Ù‚Ø±Ø¨
        question_embedding = model.encode([user_input])
        similarities = cosine_similarity(question_embedding, embeddings)[0]
        top_indices = similarities.argsort()[-3:][::-1]

        top_chunks = [texts[i] for i in top_indices]
        top_sources = [sources[i] for i in top_indices]

        # ØªØ±ÙƒÙŠØ¨ Ø§Ù„Ø¬ÙˆØ§Ø¨
        response = "**Voici une rÃ©ponse extraite des documents rÃ©glementaires :**\n\n"
        for i, chunk in enumerate(top_chunks):
            response += f"- ğŸ“„ *{top_sources[i]}*\n{chunk}\n\n"

        with st.chat_message("assistant"):
            st.markdown(response)

        st.session_state.history.append(("assistant", response))

# ------ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙŠÙ…Ù†: Upload PDF + langue ------
with right:
    st.markdown("### ğŸŒ ParamÃ¨tres")
    lang = st.selectbox("Langue", ["FranÃ§ais", "English"])
    uploaded_file = st.file_uploader("ğŸ“„ TÃ©lÃ©charger un fichier PDF", type="pdf")
    if uploaded_file:
        st.success("âœ… PDF importÃ© avec succÃ¨s ! (Traitement Ã  venir...)")
